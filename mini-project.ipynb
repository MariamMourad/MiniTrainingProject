{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"transfusion.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>whether he/she donated blood in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   whether he/she donated blood in March 2007  \n",
       "0                                           1  \n",
       "1                                           1  \n",
       "2                                           1  \n",
       "3                                           1  \n",
       "4                                           0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'whether he/she donated blood in March 2007':'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76.203209\n",
       "1    23.796791\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage calculation\n",
    "(data['target'].value_counts()/data['target'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spilitting the data into trai and test while keeping the proportion\n",
    "\n",
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=1600.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7932206068268016\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=6, DecisionTreeClassifier__min_samples_leaf=14, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-2\t0.805704804045512\tMLPClassifier(RobustScaler(input_matrix), MLPClassifier__alpha=0.0001, MLPClassifier__learning_rate_init=0.01)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 [22:30:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:567: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7932206068268016\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=6, DecisionTreeClassifier__min_samples_leaf=14, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-2\t0.8110303413400757\tDecisionTreeClassifier(PCA(input_matrix, PCA__iterated_power=5, PCA__svd_solver=randomized), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=15, DecisionTreeClassifier__min_samples_split=10)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7932206068268016\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=6, DecisionTreeClassifier__min_samples_leaf=14, DecisionTreeClassifier__min_samples_split=7)\n",
      "\n",
      "-2\t0.8110303413400757\tDecisionTreeClassifier(PCA(input_matrix, PCA__iterated_power=5, PCA__svd_solver=randomized), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=15, DecisionTreeClassifier__min_samples_split=10)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7950379266750949\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.5, GradientBoostingClassifier__max_depth=1, GradientBoostingClassifier__max_features=0.5, GradientBoostingClassifier__min_samples_leaf=2, GradientBoostingClassifier__min_samples_split=6, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.8500000000000001)\n",
      "\n",
      "-2\t0.8110303413400757\tDecisionTreeClassifier(PCA(input_matrix, PCA__iterated_power=5, PCA__svd_solver=randomized), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=15, DecisionTreeClassifier__min_samples_split=10)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [22:36:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:567: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7950379266750949\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.5, GradientBoostingClassifier__max_depth=1, GradientBoostingClassifier__max_features=0.5, GradientBoostingClassifier__min_samples_leaf=2, GradientBoostingClassifier__min_samples_split=6, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.8500000000000001)\n",
      "\n",
      "-2\t0.8110303413400757\tDecisionTreeClassifier(PCA(input_matrix, PCA__iterated_power=5, PCA__svd_solver=randomized), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=15, DecisionTreeClassifier__min_samples_split=10)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7967920353982302\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=9, DecisionTreeClassifier__min_samples_leaf=12, DecisionTreeClassifier__min_samples_split=18)\n",
      "\n",
      "-2\t0.8110303413400759\tMLPClassifier(StandardScaler(input_matrix), MLPClassifier__alpha=0.01, MLPClassifier__learning_rate_init=0.1)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 7 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7967920353982302\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=9, DecisionTreeClassifier__min_samples_leaf=12, DecisionTreeClassifier__min_samples_split=18)\n",
      "\n",
      "-2\t0.8128160556257902\tDecisionTreeClassifier(PCA(input_matrix, PCA__iterated_power=5, PCA__svd_solver=randomized), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=9, DecisionTreeClassifier__min_samples_leaf=15, DecisionTreeClassifier__min_samples_split=10)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.\n",
      "\n",
      "Generation 8 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7985777496839443\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.8, RandomForestClassifier__min_samples_leaf=15, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-2\t0.8128476611883692\tRandomForestClassifier(PCA(input_matrix, PCA__iterated_power=4, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=9, RandomForestClassifier__min_samples_split=18, RandomForestClassifier__n_estimators=100)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "\n",
      "Generation 9 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7985777496839443\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.8, RandomForestClassifier__min_samples_leaf=15, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-2\t0.8128476611883692\tRandomForestClassifier(PCA(input_matrix, PCA__iterated_power=4, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=9, RandomForestClassifier__min_samples_split=18, RandomForestClassifier__n_estimators=100)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 10 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7985777496839443\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.8, RandomForestClassifier__min_samples_leaf=15, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-2\t0.8128476611883692\tRandomForestClassifier(PCA(input_matrix, PCA__iterated_power=4, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=9, RandomForestClassifier__min_samples_split=18, RandomForestClassifier__n_estimators=100)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 11 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7985777496839443\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.8, RandomForestClassifier__min_samples_leaf=15, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-2\t0.8128476611883692\tRandomForestClassifier(PCA(input_matrix, PCA__iterated_power=4, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=9, RandomForestClassifier__min_samples_split=18, RandomForestClassifier__n_estimators=100)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 12 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7985777496839443\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.8, RandomForestClassifier__min_samples_leaf=15, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-2\t0.8128476611883692\tRandomForestClassifier(PCA(input_matrix, PCA__iterated_power=4, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=9, RandomForestClassifier__min_samples_split=18, RandomForestClassifier__n_estimators=100)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "\n",
      "Generation 13 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.7985777496839443\tRandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.8, RandomForestClassifier__min_samples_leaf=15, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-2\t0.8128476611883692\tRandomForestClassifier(PCA(input_matrix, PCA__iterated_power=4, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.5, RandomForestClassifier__min_samples_leaf=9, RandomForestClassifier__min_samples_split=18, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-3\t0.814649178255373\tRandomForestClassifier(PCA(PCA(input_matrix, PCA__iterated_power=5, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.2, RandomForestClassifier__min_samples_leaf=8, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "\n",
      "Generation 14 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8003318584070798\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.5, GradientBoostingClassifier__max_depth=1, GradientBoostingClassifier__max_features=0.5, GradientBoostingClassifier__min_samples_leaf=5, GradientBoostingClassifier__min_samples_split=6, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.8500000000000001)\n",
      "\n",
      "-2\t0.8128634639696586\tRandomForestClassifier(PCA(input_matrix, PCA__iterated_power=2, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.2, RandomForestClassifier__min_samples_leaf=8, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-3\t0.814649178255373\tRandomForestClassifier(PCA(PCA(input_matrix, PCA__iterated_power=5, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.2, RandomForestClassifier__min_samples_leaf=8, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=100)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=3 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)', 'Time (months)'] ['f0', 'f1', 'f2', 'f3']\n",
      "expected Frequency (times), Time (months), Monetary (c.c. blood), Recency (months) in input data\n",
      "training data did not have the following fields: f3, f2, f0, f1.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 15 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8075221238938053\tExtraTreesClassifier(CombineDFs(input_matrix, input_matrix), ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.9500000000000001, ExtraTreesClassifier__min_samples_leaf=3, ExtraTreesClassifier__min_samples_split=13, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "-2\t0.8128634639696586\tRandomForestClassifier(PCA(input_matrix, PCA__iterated_power=2, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.2, RandomForestClassifier__min_samples_leaf=8, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "-3\t0.814649178255373\tRandomForestClassifier(PCA(PCA(input_matrix, PCA__iterated_power=5, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.2, RandomForestClassifier__min_samples_leaf=8, RandomForestClassifier__min_samples_split=4, RandomForestClassifier__n_estimators=100)\n",
      "0.8467023172905526\n"
     ]
    }
   ],
   "source": [
    "#using TPOT to find the best model\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "pipline_optimizer = TPOTClassifier(generations=15, cv=5, random_state=42, verbosity=3)\n",
    "pipline_optimizer.fit(x_train, y_train)\n",
    "print(pipline_optimizer.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipline_optimizer.export('topt_exported_pipline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7807486631016043\n"
     ]
    }
   ],
   "source": [
    "#From what we know the best model for this data is Logistic Regression so, we will use it.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_predict = model.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.097507677769975"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the variance to improve accuracy.\n",
    "data.loc[:,\"Frequency (times)\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2131094.22986061"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,\"Monetary (c.c. blood)\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594.2242034089999"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,\"Time (months)\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scince 'Monetary (c.c. blood)' variance is very high we will normalize that column.\n",
    "data['Monetary (c.c. blood)'] = np.log(data['Monetary (c.c. blood)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>9.433484</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8.086410</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>8.294050</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>8.517193</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>8.699515</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50               9.433484             98   \n",
       "1                 0                 13               8.086410             28   \n",
       "2                 1                 16               8.294050             35   \n",
       "3                 2                 20               8.517193             45   \n",
       "4                 1                 24               8.699515             77   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "#Reapply Logistic Regression model after normalization.\n",
    "\n",
    "x1 = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1_train, x1_test, y_train, y_test = train_test_split(x1, y, test_size=0.25, random_state=0, stratify=y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(x1_train, y_train)\n",
    "y_predict = model.predict(x1_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
